{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing_utils import preprocess\n",
    "import pygam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: FLX_CN-Cha_FLUXNET2015_FULLSET_DD_2003-2005_1-3.csv\n",
      "Total rows: 1096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = preprocess('CN-Cha', 'FULLSET', '2003-2005', '1-3', 'DD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>TA_F_MDS</th>\n",
       "      <th>TA_F_MDS_QC</th>\n",
       "      <th>TA_F_MDS_NIGHT</th>\n",
       "      <th>TA_F_MDS_NIGHT_SD</th>\n",
       "      <th>TA_F_MDS_NIGHT_QC</th>\n",
       "      <th>TA_F_MDS_DAY</th>\n",
       "      <th>TA_F_MDS_DAY_SD</th>\n",
       "      <th>TA_F_MDS_DAY_QC</th>\n",
       "      <th>TA_ERA</th>\n",
       "      <th>...</th>\n",
       "      <th>GPP_DT_CUT_05</th>\n",
       "      <th>GPP_DT_CUT_16</th>\n",
       "      <th>GPP_DT_CUT_25</th>\n",
       "      <th>GPP_DT_CUT_50</th>\n",
       "      <th>GPP_DT_CUT_75</th>\n",
       "      <th>GPP_DT_CUT_84</th>\n",
       "      <th>GPP_DT_CUT_95</th>\n",
       "      <th>RECO_SR</th>\n",
       "      <th>RECO_SR_N</th>\n",
       "      <th>time_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20030101</td>\n",
       "      <td>-20.586</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-21.739</td>\n",
       "      <td>1.741</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-18.664</td>\n",
       "      <td>1.042</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-21.221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306852</td>\n",
       "      <td>0.412476</td>\n",
       "      <td>0.412476</td>\n",
       "      <td>0.412476</td>\n",
       "      <td>0.417759</td>\n",
       "      <td>0.420625</td>\n",
       "      <td>0.423614</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20030102</td>\n",
       "      <td>-19.627</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-20.293</td>\n",
       "      <td>5.425</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-18.518</td>\n",
       "      <td>4.286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-16.701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.22584</td>\n",
       "      <td>0.306388</td>\n",
       "      <td>0.306388</td>\n",
       "      <td>0.306388</td>\n",
       "      <td>0.311613</td>\n",
       "      <td>0.314466</td>\n",
       "      <td>0.317277</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>20030103</td>\n",
       "      <td>-16.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-17.949</td>\n",
       "      <td>3.095</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-15.348</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-16.642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189143</td>\n",
       "      <td>0.257863</td>\n",
       "      <td>0.257863</td>\n",
       "      <td>0.257863</td>\n",
       "      <td>0.262853</td>\n",
       "      <td>0.265588</td>\n",
       "      <td>0.268227</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20030104</td>\n",
       "      <td>-25.042</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-25.325</td>\n",
       "      <td>0.516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-24.609</td>\n",
       "      <td>0.819</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-24.689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208826</td>\n",
       "      <td>0.283592</td>\n",
       "      <td>0.283592</td>\n",
       "      <td>0.283592</td>\n",
       "      <td>0.288567</td>\n",
       "      <td>0.291287</td>\n",
       "      <td>0.293954</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20030105</td>\n",
       "      <td>-24.215</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-24.982</td>\n",
       "      <td>1.179</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-23.044</td>\n",
       "      <td>1.746</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-23.971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265409</td>\n",
       "      <td>0.358534</td>\n",
       "      <td>0.358534</td>\n",
       "      <td>0.358534</td>\n",
       "      <td>0.363935</td>\n",
       "      <td>0.366873</td>\n",
       "      <td>0.369835</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 321 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  TIMESTAMP TA_F_MDS TA_F_MDS_QC TA_F_MDS_NIGHT TA_F_MDS_NIGHT_SD  \\\n",
       "0  20030101  -20.586         1.0        -21.739             1.741   \n",
       "1  20030102  -19.627         1.0        -20.293             5.425   \n",
       "2  20030103   -16.92         1.0        -17.949             3.095   \n",
       "3  20030104  -25.042         1.0        -25.325             0.516   \n",
       "4  20030105  -24.215         1.0        -24.982             1.179   \n",
       "\n",
       "  TA_F_MDS_NIGHT_QC TA_F_MDS_DAY TA_F_MDS_DAY_SD TA_F_MDS_DAY_QC   TA_ERA  \\\n",
       "0               1.0      -18.664           1.042             1.0  -21.221   \n",
       "1               1.0      -18.518           4.286             1.0  -16.701   \n",
       "2               1.0      -15.348             1.3             1.0  -16.642   \n",
       "3               1.0      -24.609           0.819             1.0  -24.689   \n",
       "4               1.0      -23.044           1.746             1.0  -23.971   \n",
       "\n",
       "   ... GPP_DT_CUT_05 GPP_DT_CUT_16 GPP_DT_CUT_25 GPP_DT_CUT_50 GPP_DT_CUT_75  \\\n",
       "0  ...      0.306852      0.412476      0.412476      0.412476      0.417759   \n",
       "1  ...       0.22584      0.306388      0.306388      0.306388      0.311613   \n",
       "2  ...      0.189143      0.257863      0.257863      0.257863      0.262853   \n",
       "3  ...      0.208826      0.283592      0.283592      0.283592      0.288567   \n",
       "4  ...      0.265409      0.358534      0.358534      0.358534      0.363935   \n",
       "\n",
       "  GPP_DT_CUT_84 GPP_DT_CUT_95 RECO_SR RECO_SR_N time_index  \n",
       "0      0.420625      0.423614   -9999     -9999          0  \n",
       "1      0.314466      0.317277   -9999     -9999          1  \n",
       "2      0.265588      0.268227   -9999     -9999          2  \n",
       "3      0.291287      0.293954   -9999     -9999          3  \n",
       "4      0.366873      0.369835   -9999     -9999          4  \n",
       "\n",
       "[5 rows x 321 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1096, 321)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.head(), data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TA_F', 'SW_IN_F', 'LW_IN_F', 'LW_IN_JSB_F', 'VPD_F', 'PA_F', 'P_F', 'WS_F']\n",
      "['TA_ERA', 'TA_ERA_DAY', 'TA_ERA_DAY_SD', 'TA_ERA_NIGHT', 'TA_ERA_NIGHT_SD', 'TA_F', 'TA_F_DAY', 'TA_F_DAY_QC', 'TA_F_DAY_SD', 'TA_F_MDS', 'TA_F_MDS_DAY', 'TA_F_MDS_DAY_QC', 'TA_F_MDS_DAY_SD', 'TA_F_MDS_NIGHT', 'TA_F_MDS_NIGHT_QC', 'TA_F_MDS_NIGHT_SD', 'TA_F_MDS_QC', 'TA_F_NIGHT', 'TA_F_NIGHT_QC', 'TA_F_NIGHT_SD', 'TA_F_QC']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print([col for col in data.columns if col[-2:] == '_F'])\n",
    "print(sorted([col for col in data.columns if col[:2] == 'TA']))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X variables: TA, SW, VPD, WS, P, CO2 \n",
    "Y variables: NEE, GPP, RECO\n",
    "NEE = net carbon exchange -> use NEE_CUT_REF or NEE_VUT_REF\n",
    "GPP = total carbon uptake -> use GPP_DT_VUT_REF or GPP_NT_VUT_REF (or CUT)\n",
    "RECO = respiration -> RECO_DT_VUT_REF\n",
    "\n",
    "if using DT for one, use DT for another\n",
    "focus on GPP first for now\n",
    "\n",
    "remi prefers VUT\n",
    "need remote sensing information\n",
    " \n",
    "for input->output, want to predict \"current day\" accurately based on last x days, dont care the models outputs up\n",
    "until current day. \n",
    "\n",
    "instant effects: CO2, WS, VPD\n",
    "longer-term effects: SW, TA, P\n",
    "\n",
    "for memory length, try 30 days at most first\n",
    "\n",
    "DAYTIME is generated from a model, may not want to use that or compare to both daytime and nighttime\n",
    "\n",
    "if not in the site data, just dont use, but should be pretty rare\n",
    "\n",
    "normalize the variables before training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual variable selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA_F</th>\n",
       "      <th>SW_IN_F</th>\n",
       "      <th>P_F</th>\n",
       "      <th>WS_F</th>\n",
       "      <th>VPD_F</th>\n",
       "      <th>GPP_NT_VUT_REF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-20.586</td>\n",
       "      <td>107.816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.869</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.0587789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-19.627</td>\n",
       "      <td>78.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.616</td>\n",
       "      <td>-0.074822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-16.92</td>\n",
       "      <td>65.602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.921</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.0226356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-25.042</td>\n",
       "      <td>72.689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.305</td>\n",
       "      <td>0.283</td>\n",
       "      <td>-0.0606192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-24.215</td>\n",
       "      <td>92.826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.494</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.00896626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TA_F  SW_IN_F  P_F   WS_F  VPD_F GPP_NT_VUT_REF\n",
       "0  -20.586  107.816  0.0  2.869  0.561      0.0587789\n",
       "1  -19.627    78.68  0.0   1.31  0.616      -0.074822\n",
       "2   -16.92   65.602  0.0  1.921  0.388      0.0226356\n",
       "3  -25.042   72.689  0.0  3.305  0.283     -0.0606192\n",
       "4  -24.215   92.826  0.0  3.494  0.347     0.00896626"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables = ['TA_F', 'SW_IN_F', 'P_F', 'WS_F', 'VPD_F']\n",
    "labels = ['GPP_NT_VUT_REF']\n",
    "data[variables + labels].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_measurements = [col for col in data.columns if ('QC' not in col) \n",
    "                       and ('UNC' not in col) and ('METHOD' not in col)\n",
    "                      and ('SD' not in col) and ('CORR' not in col) \n",
    "                       and ('MEAN' not in col) and ('SE' not in col) and ('TIMESTAMP' not in col)\n",
    "                      and ('NEE' not in col) and ('RECO' not in col)\n",
    "                      and ('GPP' not in col)]\n",
    "def pca(df, list_of_variables, k, normalize_matrix=True, choose_by_size=True):\n",
    "    measurements = df[list_of_variables].to_numpy()\n",
    "    mu = measurements.mean(0)\n",
    "    transformed = measurements - mu\n",
    "    if normalize_matrix:\n",
    "        transformed = normalize(transformed, axis=0, norm='l1')\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(np.matmul(transformed.T, transformed))\n",
    "    if choose_by_size:\n",
    "        projection_matrix = []\n",
    "        for i in range(k):\n",
    "            max_eig = np.argmax(eigenvalues)\n",
    "            eigenvalues = np.delete(eigenvalues, max_eig)\n",
    "            projection_matrix.append(eigenvectors[:, max_eig])\n",
    "            eigenvectors = np.delete(eigenvectors, max_eig, axis=1)\n",
    "            \n",
    "        projection_matrix = np.array(projection_matrix).T\n",
    "    else:\n",
    "        projection_matrix = eigenvectors[:, 0:k]\n",
    "    pca_measurements = np.matmul(measurements, projection_matrix)\n",
    "    return pca_measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "N/A% (0 of 11) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--\n",
      " 18% (2 of 11) |####                     | Elapsed Time: 0:00:00 ETA:  00:00:00\n",
      " 36% (4 of 11) |#########                | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      " 54% (6 of 11) |#############            | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      " 72% (8 of 11) |##################       | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      " 90% (10 of 11) |#####################   | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      "100% (11 of 11) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n",
      "N/A% (0 of 11) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--\n",
      " 18% (2 of 11) |####                     | Elapsed Time: 0:00:00 ETA:  00:00:00\n",
      " 36% (4 of 11) |#########                | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      " 54% (6 of 11) |#############            | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      " 72% (8 of 11) |##################       | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      " 81% (9 of 11) |####################     | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      "100% (11 of 11) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n",
      "N/A% (0 of 11) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--\n",
      " 18% (2 of 11) |####                     | Elapsed Time: 0:00:00 ETA:  00:00:00\n",
      " 36% (4 of 11) |#########                | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      " 54% (6 of 11) |#############            | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      " 72% (8 of 11) |##################       | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      " 90% (10 of 11) |#####################   | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      "100% (11 of 11) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n",
      "N/A% (0 of 11) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--\n",
      " 18% (2 of 11) |####                     | Elapsed Time: 0:00:00 ETA:  00:00:00\n",
      " 36% (4 of 11) |#########                | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      " 54% (6 of 11) |#############            | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      " 72% (8 of 11) |##################       | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      " 90% (10 of 11) |#####################   | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      "100% (11 of 11) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n",
      "N/A% (0 of 11) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--\n",
      " 18% (2 of 11) |####                     | Elapsed Time: 0:00:00 ETA:  00:00:00\n",
      " 36% (4 of 11) |#########                | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      " 54% (6 of 11) |#############            | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      " 72% (8 of 11) |##################       | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      " 90% (10 of 11) |#####################   | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      "100% (11 of 11) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n",
      "N/A% (0 of 11) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--\n",
      "  9% (1 of 11) |##                       | Elapsed Time: 0:00:00 ETA:  00:00:00\n",
      " 18% (2 of 11) |####                     | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      " 36% (4 of 11) |#########                | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      " 54% (6 of 11) |#############            | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      " 72% (8 of 11) |##################       | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      " 90% (10 of 11) |#####################   | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      "100% (11 of 11) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TA_F', 'SW_IN_F', 'P_F', 'WS_F', 'VPD_F'] 0.8680037717876948\n"
     ]
    }
   ],
   "source": [
    "y = data[labels].to_numpy(dtype='float')\n",
    "# xn = normalize(X, axis=0)\n",
    "# gam = pygam.GAM(n_splines=len(variables)).gridsearch(X, y)\n",
    "# display(X, xn, max(xn[:, 0]))\n",
    "# gam.summary()\n",
    "# gam.statistics_['pseudo_r2']['explained_deviance']\n",
    "# plt.rcParams['figure.figsize'] = (28,8)\n",
    "# fig, axs = plt.subplots(1, len(variables))\n",
    "# titles = variables\n",
    "# for i, ax in enumerate(axs):\n",
    "#     XX = gam.generate_X_grid(term=i)\n",
    "#     pdep, confi = gam.partial_dependence(i, X=XX, width=.95)\n",
    "#     ax.plot(XX[:, i], pdep)\n",
    "#     ax.plot(XX[:, i], confi[:, 0], c='grey', ls='--')\n",
    "#     ax.plot(XX[:, i], confi[:, 1], c='grey', ls='--')\n",
    "#     ax.set_title(titles[i],fontsize=26)\n",
    "# plt.show()\n",
    "variable_subsets = []\n",
    "for i in range(4, len(variables)+1):\n",
    "    for c in itertools.combinations(variables, i):\n",
    "        variable_subsets += [list(c)]\n",
    "variable_subsets\n",
    "\n",
    "max_pseudo_r2 = float('-inf')\n",
    "best_subset = None\n",
    "for ss in variable_subsets:\n",
    "    X = data[ss].to_numpy(dtype='float')\n",
    "    gam = pygam.GAM(n_splines=len(ss)).gridsearch(X, y)\n",
    "    if gam.statistics_['pseudo_r2']['explained_deviance'] > max_pseudo_r2:\n",
    "        max_pseudo_r2 = gam.statistics_['pseudo_r2']['explained_deviance']\n",
    "        best_subset = ss\n",
    "print(best_subset, max_pseudo_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TA_F', 'SW_IN_F', 'P_F', 'WS_F', 'VPD_F']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "class TimeseriesSampler(Sampler):\n",
    "    \"\"\"Samples sequences from the dataset using the given window size and step size\n",
    "        data_source (Dataset): dataset to sample from\n",
    "    \"\"\"\n",
    "    def __init__(self, data_source, window_size=5, step_size=1, shuffle=False):\n",
    "        self.data_source = data_source\n",
    "        self.windows = []\n",
    "        for i in range(0, len(data_source)-window_size+1, step_size):\n",
    "            self.windows.append(list(range(i, i+window_size)))\n",
    "        if shuffle:\n",
    "            random.shuffle(self.windows)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return iter(self.windows)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_source)\n",
    "\n",
    "sequence_length = 10\n",
    "split_frac = 0.9\n",
    "k = 5\n",
    "\n",
    "print(variables)\n",
    "num_key_variables = len(variables)\n",
    "# processed = pd.DataFrame(pca(data, variables, num_key_variables))\n",
    "processed = data[variables + labels].iloc[0:100].astype('float32')\n",
    "# processed[labels] = data[labels]\n",
    "# processed = processed.iloc[0:100]\n",
    "\n",
    "train_indexes, val_indexes, test_split_index = split_dataset(processed, split_frac, k)\n",
    "test = processed.iloc[test_split_index-sequence_length:]\n",
    "\n",
    "train = processed.iloc[train_indexes[-1]]\n",
    "val = processed.iloc[val_indexes[-1]]\n",
    "train_data = TensorDataset(torch.from_numpy(train[variables].to_numpy()), \n",
    "                           torch.from_numpy(train[labels].to_numpy()))\n",
    "val_data = TensorDataset(torch.from_numpy(val[variables].to_numpy()),\n",
    "                         torch.from_numpy(val[labels].to_numpy()))\n",
    "test_data = TensorDataset(torch.from_numpy(test[variables].to_numpy()), \n",
    "                          torch.from_numpy(test[labels].to_numpy()))\n",
    "\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_data, shuffle=False, batch_size=batch_size,\n",
    "                         sampler=TimeseriesSampler(train_data, sequence_length+1, shuffle=True))\n",
    "val_loader = DataLoader(val_data, shuffle=False, batch_size=batch_size,\n",
    "                       sampler=TimeseriesSampler(val_data, sequence_length+1))\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size,\n",
    "                        sampler=TimeseriesSampler(test_data, sequence_length+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, l in train_loader:\n",
    "#     print(i)\n",
    "#     print(l)\n",
    "#     print(l.squeeze()[-1])\n",
    "target_variables = ['TA_F', 'SW_IN_F', 'P_F', 'WS_F', 'VPD_F', 'CO2_F']\n",
    "backup_variables = {'TA_F' : 'TA_F_MDS', 'SW_IN_F': 'SW_IN_F_MDS', 'P_F': 'P_F_MDS', 'CO2_F': 'CO2_F_MDS', 'WS_F': 'WS_F_MDS', 'VPD_F': 'VPD_F_MDS'}\n",
    "variables = []\n",
    "for v in target_variables:\n",
    "    if v in data.columns:\n",
    "        variables.append(v)\n",
    "    elif backup_variables[v] in data.columns:\n",
    "        variables.append(backup_variables[v])\n",
    "variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        lstm_out, hidden = self.lstm(x, hidden)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        out = out.view(batch_size, -1)\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.013070322573184967"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size = 1\n",
    "hidden_dim = 512\n",
    "n_layers = 3\n",
    "\n",
    "model = SimpleLSTM(num_key_variables, output_size, hidden_dim, n_layers)\n",
    "model.to(device)\n",
    "\n",
    "model.zero_grad()\n",
    "inputs = torch.zeros([batch_size, sequence_length, num_key_variables], dtype=torch.float32)\n",
    "lbls = torch.zeros([batch_size, 1], dtype=torch.float32)\n",
    "h = model.init_hidden(batch_size)\n",
    "h = ([e.data for e in h])\n",
    "output, h = model(inputs, h)\n",
    "output.squeeze()[-1].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 1\n",
    "hidden_dim = 512\n",
    "n_layers = 3\n",
    "\n",
    "model = SimpleLSTM(num_key_variables, output_size, hidden_dim, n_layers)\n",
    "model.to(device)\n",
    "\n",
    "lr=0.0005\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "epochs = 10\n",
    "counter = 0\n",
    "print_every = int(len(train_loader)/2)\n",
    "clip = 5\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    h = model.init_hidden(batch_size)\n",
    "    \n",
    "    for inputs, lbls in train_loader:\n",
    "        counter += 1\n",
    "        h = tuple([e.data for e in h])\n",
    "        inputs, lbls = inputs.to(device), lbls.squeeze().to(device)\n",
    "        model.zero_grad()\n",
    "        output, h = model(inputs, h)\n",
    "        # we only care about the last output for now\n",
    "        loss = criterion(output.squeeze()[-1], lbls.float()[-1])\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if counter%print_every == 0:\n",
    "            val_h = model.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            for inp, lab in val_loader:\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "                inp, lab = inp.to(device), lab.squeeze().to(device)\n",
    "                out, val_h = model(inp, val_h)\n",
    "                val_loss = criterion(out.squeeze()[-1], lab.float()[-1])\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "            model.train()\n",
    "            mean_val_loss = np.mean(val_losses)\n",
    "            print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(mean_val_loss))\n",
    "\n",
    "            if mean_val_loss <= valid_loss_min:\n",
    "                torch.save(model.state_dict(), './state_dict.pt')\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,mean_val_loss))\n",
    "                valid_loss_min = mean_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses = []\n",
    "test_predictions = []\n",
    "h = model.init_hidden(batch_size)\n",
    "\n",
    "model.eval()\n",
    "for inputs, truth in test_loader:\n",
    "    h = tuple([each.data for each in h])\n",
    "    inputs, truth = inputs.to(device), truth.to(device)\n",
    "    output, h = model(inputs, h)\n",
    "    pred = output.squeeze()[-1]\n",
    "    test_loss = criterion(pred, truth.float()[-1])\n",
    "    test_losses.append(test_loss.item())\n",
    "    test_predictions.append(pred.item())\n",
    "\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "\n",
    "training_predictions = []\n",
    "h = model.init_hidden(batch_size)\n",
    "\n",
    "all_train = processed.iloc[np.append(train_indexes[-1], val_indexes[-1])]\n",
    "all_train_data = TensorDataset(torch.from_numpy(all_train[variables].to_numpy()), \n",
    "                           torch.from_numpy(all_train[labels].to_numpy()))\n",
    "all_training_data_loader = DataLoader(all_train_data, shuffle=False, batch_size=batch_size,\n",
    "                                     sampler=TimeseriesSampler(all_train_data, sequence_length+1, shuffle=False))\n",
    "\n",
    "model.eval()\n",
    "for x, y in all_training_data_loader:\n",
    "    h = tuple([each.data for each in h])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    output, h = model(x, h)\n",
    "    pred = output.squeeze()[-1]\n",
    "    training_predictions.append(pred.item())\n",
    "\n",
    "offset = sequence_length + 1\n",
    "train_len = len(training_predictions)\n",
    "test_len = len(test_predictions)\n",
    "x = range(sequence_length + train_len + test_len)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Predictions vs. Ground Truth')\n",
    "plt.xlabel('Days since 2003-01-01')\n",
    "sns.lineplot(x=x, y=processed[labels[0]], label='ground truth')\n",
    "sns.lineplot(x=x, y=(([np.nan] * sequence_length) + training_predictions + ([np.nan] * test_len)), \n",
    "             label='train predictions')\n",
    "sns.lineplot(x=x, y=([np.nan] * (train_len + sequence_length) ) + test_predictions, \n",
    "             label='test predictions', color='red')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
